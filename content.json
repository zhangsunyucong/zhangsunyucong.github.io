{"meta":{"title":"长孙雨聪--七星上将","subtitle":"坚持不懈，必有回响。","description":"广西科技大学10级，Android工程师一枚。","author":"长孙雨聪--七星上将","url":"http://zhangsunyucong.top"},"pages":[{"title":"关于","date":"2017-12-04T06:43:27.000Z","updated":"2018-01-09T09:35:02.386Z","comments":false,"path":"about/index.html","permalink":"http://zhangsunyucong.top/about/index.html","excerpt":"","text":"个人简介 网名：zhangsunyucong 学历：全日制本科 专业：数学与应用数学 星座：天蝎座 职位：Android开发 所在地：深圳南山区科技园 技术背景 java、js、html，android、nodejs、python，了解nodejs，python 座右铭坚持不懈，必有回响 联系方式 邮箱：969887864@qq.com"},{"title":"标签","date":"2018-01-09T09:35:02.387Z","updated":"2018-01-09T09:35:02.387Z","comments":false,"path":"tags/index.html","permalink":"http://zhangsunyucong.top/tags/index.html","excerpt":"","text":""},{"title":"音乐","date":"2017-12-15T09:55:49.000Z","updated":"2018-01-09T09:35:02.386Z","comments":true,"path":"music/index.html","permalink":"http://zhangsunyucong.top/music/index.html","excerpt":"","text":"var options = {\"narrow\":false,\"autoplay\":true,\"showlrc\":3,\"mode\":\"random\",\"mutex\":true,\"theme\":\"#e6d0b2\",\"preload\":\"metadata\",\"listmaxheight\":\"513px\",\"music\":[{\"title\":\"够钟\",\"pic\":\"http://o8bym0zmt.bkt.clouddn.com/%E5%91%A8%E6%9F%8F%E8%B1%AAone.jpg\",\"author\":\"周柏豪\",\"url\":\"http://o8bym0zmt.bkt.clouddn.com/%E5%91%A8%E6%9F%8F%E8%B1%AA%20-%20%E5%A4%9F%E9%92%9F.mp3\"},{\"title\":\"宏愿\",\"author\":\"周柏豪\",\"pic\":\"http://o8bym0zmt.bkt.clouddn.com/%E5%91%A8%E6%9F%8F%E8%B1%AAone.jpg\",\"url\":\"http://o8bym0zmt.bkt.clouddn.com/%E5%91%A8%E6%9F%8F%E8%B1%AA%20-%20%E5%AE%8F%E6%84%BF.mp3\"},{\"title\":\"自由意志\",\"author\":\"周柏豪\",\"pic\":\"http://o8bym0zmt.bkt.clouddn.com/%E5%91%A8%E6%9F%8F%E8%B1%AAone.jpg\",\"url\":\"http://o8bym0zmt.bkt.clouddn.com/%E5%91%A8%E6%9F%8F%E8%B1%AA%20-%20%E8%87%AA%E7%94%B1%E6%84%8F%E5%BF%97.mp3\"},{\"title\":\"Beautiful In White\",\"pic\":\"http://o8bym0zmt.bkt.clouddn.com/westlife.jpg\",\"author\":\"Westlife\",\"url\":\"http://o8bym0zmt.bkt.clouddn.com/Westlife%20-%20Beautiful%20In%20White.mp3\"}]}; options.element = document.getElementById(\"aplayer1\"); new APlayer(options);"}],"posts":[{"title":"Android的MotionEvent事件分发机制","slug":"android-event","date":"2018-01-10T00:41:26.000Z","updated":"2018-01-12T06:03:01.102Z","comments":true,"path":"2018/01/10/android-event/","link":"","permalink":"http://zhangsunyucong.top/2018/01/10/android-event/","excerpt":"","text":"android事件的源头在哪里？当用户触摸屏幕或者按键等时，形成事件，事件经过linux底层Event节点捕获之后，一直传到android应用层。中间传递的过程不是本文的重点，我也不是很清楚（哈哈哈）。本文的重点是事件在应用层的分发机制。 事件在View树中的分发过程View树： 在Android中，事件的分发过程就是MotionEvent在view树分发的过程。默认是中从上而下，然后从下而上的传递的，直到有view、viewgroup或者Activity处理事件为止。 为什么要先从上而下？是为了在默认情况下，屏幕上层叠的所有控件都有机会处理事件。这个阶段我们称为事件下发阶段。 为什么要从下而上？是为了在从上而下分发时，事件没有控件处理时，再从下而上冒泡事件，是否有控件愿意处理事件。如果中间没有控件处理，事件就只能由Acitivity处理了。这个阶段我们称为事件的冒泡阶段。 准备事件序列：从用户手指触摸屏幕开始，经过滑动到手指离开屏幕。这个操作产生了一个dowm事件，一系列move事件，最后一个up事件结束。我们把这一个操作产生的事件称为一个事件序列。 Acitivity中和事件传递有关的函数事件分发：dispatchTouchEvent事件处理：onTouchEvent ViewGrop中和事件传递有关的函数事件分发：dispatchTouchEvent事件拦截：onInterceptTouchEvent事件处理：onTouchEvent View中和事件传递有关的函数事件分发：dispatchTouchEvent事件处理：onTouchEvent 从上面可以看出，ViewGrop中多了事件拦截onInterceptTouchEvent函数，是为了询问自己是否拦截事件（在事件分发中询问），如果没有拦截就传递事件给直接子view，如果拦截就将事件交给自己的事件处理函数处理。View中没有事件拦截函数，因为view是在view树中的叶节点，已经没有子view。 下面是先进行源码分析，然后再验证得出一些结论。代码迟点上传github。用图表示布局的层级关系： 这里分析事件的分发过程，是从down事件的分发开始，以及分析它在两个阶段的传递过程：下发阶段和冒泡阶段。 事件下发阶段（1）在Acitvity中的源码分析： Activity#dispatchTouchEvent 123456789public boolean dispatchTouchEvent(MotionEvent ev) &#123; if (ev.getAction() == MotionEvent.ACTION_DOWN) &#123; onUserInteraction(); &#125; if (getWindow().superDispatchTouchEvent(ev)) &#123; return true; &#125; return onTouchEvent(ev);&#125; 在第4行，Acivity将事件传递给了Window，Window是一个抽象类。在手机系统中它的实现是PhoneWindow.下面进入PhoneWindow中。 PhoneWindow#superDispatchTouchEvent1234@Overridepublic boolean superDispatchTouchEvent(MotionEvent event) &#123; return mDecor.superDispatchTouchEvent(event);&#125; 从上面可以看出，事件已经从Acitivity到PhoneWindow，再传到了DecorView。DecorView是一个继承FrameLayout的ViewGroup，从而事件进入了View树的传递。 重写在Acitvity中的事件传递方法 重写Activity#dispatchTouchEvent：1、返回false，事件不分发，所有事件在Acitivity的分发函数中就中断（真的不见了），连Acitivity的事件处理函数都到达不了。2、返回true，所有事件在Acitivity的分发函数中就中断，和false一样3、返回父函数方法，事件就传给直接子view分发 （2）在ViewGruop中的源码分析：ViewGruop#dispatchTouchEvent12345678910111213141516171819202122232425262728final int action = ev.getAction();final int actionMasked = action &amp; MotionEvent.ACTION_MASK;// Handle an initial down.if (actionMasked == MotionEvent.ACTION_DOWN) &#123; // Throw away all previous state when starting a new touch gesture. // The framework may have dropped the up or cancel event for the previous gesture // due to an app switch, ANR, or some other state change. cancelAndClearTouchTargets(ev); resetTouchState();&#125;// Check for interception.final boolean intercepted;if (actionMasked == MotionEvent.ACTION_DOWN || mFirstTouchTarget != null) &#123; final boolean disallowIntercept = (mGroupFlags &amp; FLAG_DISALLOW_INTERCEPT) != 0; if (!disallowIntercept) &#123; intercepted = onInterceptTouchEvent(ev); ev.setAction(action); // restore action in case it was changed &#125; else &#123; intercepted = false; &#125;&#125; else &#123; // There are no touch targets and this action is not an initial down // so this view group continues to intercept touches. intercepted = true;&#125; 在5-11行，是每个新的事件系列开始前，会重置事件相关的状态。这里我们关注两个地方。第一个是第17行的disallowIntercept标志，第二个是第19行调用了事件拦截函数，询问是否拦截事件。 ViewGruop#onInterceptTouchEvent123456789public boolean onInterceptTouchEvent(MotionEvent ev) &#123; if (ev.isFromSource(InputDevice.SOURCE_MOUSE) &amp;&amp; ev.getAction() == MotionEvent.ACTION_DOWN &amp;&amp; ev.isButtonPressed(MotionEvent.BUTTON_PRIMARY) &amp;&amp; isOnScrollbarThumb(ev.getX(), ev.getY())) &#123; return true; &#125; return false;&#125; onInterceptTouchEvent的代码很简单。 重写在ViewGroup中的事件传递方法重写ViewGroup#dispatchTouchEvent：1、返回false，不分发，down事件给父ViewGroup处理，以后的事件全部直接通过父ViewGroup分发函数给父ViewGroup的事件处理函数处理。2、返回true，则所有的事件都从头来到这里就中断，不见了。3、返回父函数方法，看下面拦截函数 重写ViewGroup#onInterceptTouchEvent（询问是否拦截）：1、返回true，就调用处理函数，在处理函数中是否消耗down事件2、返回false，是否是最后一个view？否，down事件就分发给子View；是，就调用一次它的处理函数，进入冒泡阶段（就是一寸事件处理函数调用）3、返回父函数的方法，和返回false一样 重写ViewGroup的onTouchEvent，当down事件来到中onTouchEvent时，1、返回true，就消耗down事件，后面全部事件从头分发到处理函数（不用再询问是否拦截）。后面的事件根据是否消耗而是否消失（不消耗就消失），消失的所有事件由Acitivity处理（注意消失的事件也是从头传递到这里再传给Acitivity的）。2、返回false，将down事件冒泡回去，看谁会处理。3、返回父函数方法，是默认不消耗。 （3）在View中的源码分析：View#dispatchTouchEvent 12345678910111213141516if (onFilterTouchEventForSecurity(event)) &#123; if ((mViewFlags &amp; ENABLED_MASK) == ENABLED &amp;&amp; handleScrollBarDragging(event)) &#123; result = true; &#125; //noinspection SimplifiableIfStatement ListenerInfo li = mListenerInfo; if (li != null &amp;&amp; li.mOnTouchListener != null &amp;&amp; (mViewFlags &amp; ENABLED_MASK) == ENABLED &amp;&amp; li.mOnTouchListener.onTouch(this, event)) &#123; result = true; &#125; if (!result &amp;&amp; onTouchEvent(event)) &#123; result = true; &#125;&#125; 这里关注的地方是，第9行和第13行。第9行是当前view如果设置了onTouch事件，并且它返回了true，那它就直接将result设置为true，事件就消耗了，不会再继续传递下去，只到达onTouch。第13行，是事件处理函数。可以看出onTouch是优先于onTouchEvent的。 View#dispatchTouchEvent 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455....final boolean clickable = ((viewFlags &amp; CLICKABLE) == CLICKABLE || (viewFlags &amp; LONG_CLICKABLE) == LONG_CLICKABLE) || (viewFlags &amp; CONTEXT_CLICKABLE) == CONTEXT_CLICKABLE;... if (clickable || (viewFlags &amp; TOOLTIP) == TOOLTIP) &#123; switch (action) &#123; case MotionEvent.ACTION_UP: mPrivateFlags3 &amp;= ~PFLAG3_FINGER_DOWN; if ((viewFlags &amp; TOOLTIP) == TOOLTIP) &#123; handleTooltipUp(); &#125; if (!clickable) &#123; removeTapCallback(); removeLongPressCallback(); mInContextButtonPress = false; mHasPerformedLongPress = false; mIgnoreNextUpEvent = false; break; &#125; boolean prepressed = (mPrivateFlags &amp; PFLAG_PREPRESSED) != 0; if ((mPrivateFlags &amp; PFLAG_PRESSED) != 0 || prepressed) &#123; // take focus if we don&apos;t have it already and we should in // touch mode. boolean focusTaken = false; if (isFocusable() &amp;&amp; isFocusableInTouchMode() &amp;&amp; !isFocused()) &#123; focusTaken = requestFocus(); &#125; if (prepressed) &#123; // The button is being released before we actually // showed it as pressed. Make it show the pressed // state now (before scheduling the click) to ensure // the user sees it. setPressed(true, x, y); &#125; if (!mHasPerformedLongPress &amp;&amp; !mIgnoreNextUpEvent) &#123; // This is a tap, so remove the longpress check removeLongPressCallback(); // Only perform take click actions if we were in the pressed state if (!focusTaken) &#123; // Use a Runnable and post this rather than calling // performClick directly. This lets other visual state // of the view update before click actions start. if (mPerformClick == null) &#123; mPerformClick = new PerformClick(); &#125; if (!post(mPerformClick)) &#123; performClick(); &#125; &#125; ... view根据是否可以点击等等一系列判断什么的。这里关注up事件中的第42-53行，有performClick。 View#performClick1234567891011121314151617public boolean performClick() &#123; final boolean result; final ListenerInfo li = mListenerInfo; if (li != null &amp;&amp; li.mOnClickListener != null) &#123; playSoundEffect(SoundEffectConstants.CLICK); li.mOnClickListener.onClick(this); result = true; &#125; else &#123; result = false; &#125; sendAccessibilityEvent(AccessibilityEvent.TYPE_VIEW_CLICKED); notifyEnterOrExitForAutoFillIfNeeded(true); return result;&#125; 如果view设置了mOnClickListener，即点击事件，会调用view的点击事件。如果在父view中拦截了up事件，使up事件到达不了这里，会使view的点击事件失效。 可以知道，onTouch是优先于onTouchEvent，onTouchEvent优先于onclick。 事件冒泡阶段当down事件到达了最后一个子view，如果仍然没有view愿意处理它，就调用一次最后一个子view的事件处理函数，是否处理dowm事件，如果不处理，就一直冒泡回去，直到有view的onTouchEvent处理为止。如果都不处理，就只有Acitivity自己处理了。整个事件冒泡阶段就是一串onTouchEvent的回溯过程，自下而上。","categories":[],"tags":[{"name":"android","slug":"android","permalink":"http://zhangsunyucong.top/tags/android/"}]},{"title":"《火影忍者》--鸣人和雏田","slug":"huoying","date":"2017-12-28T07:45:26.000Z","updated":"2018-01-12T06:03:01.104Z","comments":true,"path":"2017/12/28/huoying/","link":"","permalink":"http://zhangsunyucong.top/2017/12/28/huoying/","excerpt":"那个时候所有人只是把鸣人当做孤儿看待。他长相最多只能算一般，成绩吊车尾，缺家教，没才华，家世没有，血统没有，智商没有，然后还调皮爱恶作剧。","text":"那个时候所有人只是把鸣人当做孤儿看待。他长相最多只能算一般，成绩吊车尾，缺家教，没才华，家世没有，血统没有，智商没有，然后还调皮爱恶作剧。 除非傻子才会喜欢那时的鸣人。但是雏田硬是喜欢上了，这一喜欢，不仅坚持了好多年，而且还因为这份喜欢，改变了自己。 雏田她硬是透过了种种外在因素，一眼就看清楚了鸣人的内在：阳光，乐观，有梦想，能努力，坚持到底，不服输。可以看出她是多么强大的主见，不理会别人看法的主见。 雏田总是在默默注视着鸣人，一直支持着他，追赶着他。 你知道当你一个人面临绝望的时候，此时却有一个义无反顾的身影挡在你面前，保护你，是什么感觉吗？ 在佩恩来袭，鸣人最为脆弱的时候，挡在他身前保护他。鸣人在十尾的木遁下无处可逃时，她也毅然决然的挡在他身前。那么一个弱弱小小的女孩子，她的勇敢和坚毅却超乎寻常的强大。 两个人第一次去约会，鸣人却因为没钱请不起高级料理，不知道怎么开口。雏田用白眼看鸣人的钱包，然后主动说去吃一乐拉面。 忍界大战开始中。《宁次之死》，让雏田和鸣人打击沉重，鸣人的意志开始动摇，在鸣人内心的防线即将崩溃时，雏田强忍失去亲人的伤痛，一巴掌打醒鸣人，告诉鸣人是宁次用生命换取他活下去的用意，告诉鸣人要清醒，要秉持自己的信念，不要放弃自己的忍道，鼓励他带领大家继续战斗。雏田她看似弱不禁风的外表下其实有着很强大的内心和很坚强的意志。忍界大战胜利后，鸣人成为救世主。 多年之后，鸣人的儿子博人问鸣人：“爸爸，你年轻的时候干了什么伟大的事啊？”鸣人摸了摸他的头，然后说：“我用了十五年，帮我曾经最喜欢的女生追回了她的丈夫。”儿子又问：“那妈妈呢？”鸣人眼里光线都温柔了：“妈妈坚持爱到了我爱她的那一天。“","categories":[],"tags":[{"name":"生活","slug":"生活","permalink":"http://zhangsunyucong.top/tags/生活/"}]},{"title":"android和nodejs搭建一个应用","slug":"android-encryption","date":"2017-12-25T06:47:12.000Z","updated":"2018-01-12T06:03:01.104Z","comments":true,"path":"2017/12/25/android-encryption/","link":"","permalink":"http://zhangsunyucong.top/2017/12/25/android-encryption/","excerpt":"","text":"背景为什么想写这一篇文章呢？做android的开发也有两年的时间了，就想把以前学到的一些东西记录下来。于是首先就想在github.com上开一个项目MVPDemo,将一些自己认为比较好的知识点都串联起来。 主要目的：1、初步认识和使用MVP、dagger2和rxJava22、使用对称和非对称加密加强前端与后台的安全机制3、前后台的socket交互实现 其中3、中的socket实现，我专门建了一个github仓库NodeTestDemo，这个仓库不仅仅实现了前端的普通接口，还提供了一个socket服务。 android端实现1、采用了MVP架构，使用dagger2对象依赖注入框架解耦MVP的各个组件2、界面采用了autolayout进行兼容适配，UI尺寸标准是720*1080.页面效果仿微信。3、rxjava2、rxlifecycle2，rxbinding2等Rx系列的初级使用4、与后台服务器接口交互使用了retrofit2，交互的数据格式为json5、自定义retrofit2的ConverterFactory和Interceptor实现统一加解密交互的数据流程6、事件总线eventbus3、控件注入框架butterknife、GreenDao3对象关系映射数据库的使用7、socket的前端简单实现8、PDF文档库android-pdf-viewer的使用9、使用jsoup解析csdn网站的html页面获取博主的博客信息10、接入bugly。可以使用budly跟踪异常奔溃信息和bugly基于tinker的热修复。11、接入腾讯X5内核浏览器服务代替原生的webview12、页面路由Arouter的初步使用13、app端出现异常，在杀死应用前，启动异常页面并允许用户点击重启14、Cmake的使用。可以将敏感或者需要保密的数据使用jni保护，如第三方开发者平台的appid等 后台安全数据安全交互机制1、后台服务器使用了leancloud和nodejs搭建。nodejs服务器源码2、android端的数据加密流程：（1）生产用RSA加解密的公钥和私钥，保存好。将公钥分配给前端。（2）后台为android终端分配appid，同时后台也保存一份appid，应用每次启动时产生一个AES加密的appkey（key每次启动都是不同）（3）将请求参数按参数名的字典顺序排序得到signString，然后在signString后追加appid，再使用appkey将字符串进行AES加密得到sign。（4）将appkey经过RSA公钥加密后得到aesKey。再将aesKey（RSA加密）、sign和加密signString传给后台。（5）后台使用RSA私钥解密aesKey得到appkey，使用appkey解密sign和signString加appi得到的两个字符串，将两个字符串验证对比。（6）如果要求服务器只允许一定时间范围内的请求，可以添加时间戳作为接口签名的一部分，防止重放攻击。","categories":[],"tags":[{"name":"android","slug":"android","permalink":"http://zhangsunyucong.top/tags/android/"}]},{"title":"二进制和种类","slug":"binary-classify","date":"2017-12-22T01:20:13.000Z","updated":"2018-01-12T06:03:01.105Z","comments":true,"path":"2017/12/22/binary-classify/","link":"","permalink":"http://zhangsunyucong.top/2017/12/22/binary-classify/","excerpt":"","text":"前言话回我刚刚毕业来到深圳时，作为一个android菜鸟在一个大神波哥的指导下，学到了很多东西。其中，二进制和分类就是我印象最深的。想按自己理解记录一下。 想一下，有这样的需求：一个物体有一个种类属性，它这个属性有很多相互独立可以相加的值，也就是它有很多种情况，而且一个物体可同时具有其中一个或者多个情况。而我们想用一个数字就表示它的所有情况（这就是数学思维，总把东西抽象化）。 来个具体的，用于表示一个人是否有高血压，高血糖，高血脂这种属性。这个属性可以有各种情况的值，一个人可以只是有高血压、高血糖或者高血脂，也可以有“三高”。那我们如何用一个十进制的值来表示一个人的这个属性的各种情呢？ 我们可以让十进制数字的二进制表示的每一位代表一种情况，运用二进制的位运算来表示和判断它的各种情况。 思路分析还是上面举的例子。二进制的每一位代表一种情况，三种情况我们可以用二进制的四位表示就可以。其他更多的情况，可以用更多的位来表示。我们约定结果的格式表示为：二进制，十进制。 高血压： 0001，1 。—表示一个人只有高血压高血糖： 0010，2 。—表示一个人只有高血糖高血脂： 0100，4 。—表示一个人只有高血脂 那如何表示其他各种情况呢？ 表示一个人有高血压和高血糖：0001 | 0010 = 0011，3表示一个人有高血压和高血脂：0001 | 0100 = 0101，5表示一个人有高血糖和高血脂：0010 | 0100 = 0110，6表示一个人有高血压、高血糖和高血脂： 0001 | 0010 | 0100 = 0111，7 我们就说，这就是各种情况“相加”。 如果要从多种情况中减除一种或者多种情况，又如何操作呢？比如代表“三高”的7，我们如何从中减除高血压这种情况。 7 &amp; (~0001) = 0111 &amp; (~0001) = 0111 &amp; 1110 = 0110，6 说明：自身取“非”是为了不影响原来其他的各种情况，只改变自身那种情况的位。减除多种情况，以此类推。这就是情况的“相减” 如果给我们一个十进制：7，我们又如何知道它表示有多少种情况呢？ 1、是否有高血压 0001？7 &amp; 0001 = 0001 即 0111 &amp; 0001 = 00012、是否有高血糖？7 &amp; 0010 = 0010 即 0111 &amp; 0010 = 00103、是否有高血脂？7 &amp; 0100 = 0100 即 0111 &amp; 0100 = 0100 这实际就是，位的与运算是否等于自身。这就是各种情况的判断方法。","categories":[],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"http://zhangsunyucong.top/tags/基础知识/"}]},{"title":"读《人类简史》和《未来简史》","slug":"about-history","date":"2017-12-12T03:31:48.000Z","updated":"2018-01-12T06:03:01.109Z","comments":true,"path":"2017/12/12/about-history/","link":"","permalink":"http://zhangsunyucong.top/2017/12/12/about-history/","excerpt":"","text":"读前提取论点 人类因为自然的一次偶然的基础而出现。智人摆脱了基因的宿命，开始用语言交流，可以说故事了，慢慢产生了各种概念，如神，社会，国家，配偶，金钱等等。 智慧的产生，源于人的反思和内心。 现在人只是生活在自己编造的故事里，正是因为故事才赋予人以意义。 从历史谈到现在，指出万物皆是算法，不同的算法，只是意识的有无和不同。 未来很多东西会被人类写的算法所取代，甚至会出现新的人类阶级：无用阶级和超人类。 超人类甚至可以足够强大，是长生的，可以操作万物，记忆不再只存于大脑，甚至可以存在于“云”中。 最后，这两本书其实也是正在述说着故事。未完待续。。。","categories":[],"tags":[{"name":"阅读","slug":"阅读","permalink":"http://zhangsunyucong.top/tags/阅读/"}]},{"title":"使用nginx负载均衡nodejs","slug":"node-and-nginx","date":"2017-12-06T02:59:08.000Z","updated":"2018-01-12T06:03:01.107Z","comments":true,"path":"2017/12/06/node-and-nginx/","link":"","permalink":"http://zhangsunyucong.top/2017/12/06/node-and-nginx/","excerpt":"","text":"前言这篇文章适合熟悉nodejs的同学观看。主要是关于如何使用nginx做反向代理和负载均衡nodejs的多个实例的配置流程，nodejs实例可以是分布在同一台主机上或者不同的主机上的多个实例。 主要内容有 在同一主机创建nodejs多个实例 详细讲解ngnix.conf文件的每项配置的作用 在同一主机创建nodejs多个实例我的nodejs环境： window 7 64位 nodejs v8.1.3 webstorm 2017版 根目录/server.js文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115&apos;use strict&apos;;var express = require(&apos;express&apos;);var timeout = require(&apos;connect-timeout&apos;);var path = require(&apos;path&apos;);var cookieParser = require(&apos;cookie-parser&apos;);var bodyParser = require(&apos;body-parser&apos;);var app = express();// 设置模板引擎,路径在根目录+public中app.set(&apos;views&apos;, path.join(__dirname, &apos;public&apos;));app.set(&apos;view engine&apos;, &apos;ejs&apos;);app.use(express.static(&apos;public&apos;));app.use(express.static(path.join(__dirname, &apos;public&apos;)));// 设置默认超时时间app.use(timeout(&apos;15s&apos;));//请求体app.use(bodyParser.json());app.use(bodyParser.urlencoded(&#123; extended: false &#125;));//cookieapp.use(cookieParser());//注册HTTP消息头部信息app.use( function(req, res, next) &#123; res.set( &#123; &apos;Content-Type&apos;: &apos;text/html&apos;, &apos;Access-Control-Allow-Origin&apos;: &apos;*&apos;, &apos;Access-Control-Allow-Rememberme&apos;: true, &apos;Access-Control-Allow-HttpOnly&apos;: false, &apos;Access-Control-Allow-Methods&apos;: &apos;POST, GET, PUT, DELETE, OPTIONS&apos;, &apos;Access-Control-Allow-Credentials&apos;: true, //false, &apos;Access-Control-Max-Age&apos;: &apos;86400&apos;, // 24 hours &apos;Access-Control-Allow-Headers&apos;: &apos;X-Requested-With, X-HTTP-Method-Override, Content-Type, Accept&apos; &#125; ); //decodeURI(req.url) console.log(&apos;%s %s&apos;, req.method, req.url); next(); &#125;);//首页app.get(&apos;/&apos;, function(req, res) &#123; res.render(&apos;index1&apos;, &#123; currentTime: new Date() &#125;);&#125;);app.use(function(req, res, next) &#123; // 如果任何一个路由都没有返回响应，则抛出一个 404 异常给后续的异常处理器 if (!res.headersSent) &#123; var err = new Error(&apos;Not Found&apos;); err.status = 404; next(err); &#125;&#125;);// 错误处理app.use(function(err, req, res, next) &#123; if (req.timedout &amp;&amp; req.headers.upgrade === &apos;websocket&apos;) &#123; // 忽略 websocket 的超时 return; &#125; var statusCode = err.status || 500; if (statusCode === 500) &#123; console.error(err.stack || err); &#125; if (req.timedout) &#123; console.error(&apos;请求超时: url=%s, timeout=%d, 请确认方法执行耗时很长，或没有正确的 response 回调。&apos;, req.originalUrl, err.timeout); &#125; res.status(statusCode); // 默认不输出异常详情 var error = &#123;&#125;; if (app.get(&apos;env&apos;) === &apos;development&apos;) &#123; // 如果是开发环境，则将异常堆栈输出到页面，方便开发调试 error = err; &#125; res.render(&apos;error&apos;, &#123; message: err.message, error: error &#125;);&#125;);function catchGlobalError(err) &#123; // 注册全局未捕获异常处理器 process.on(&apos;uncaughtException&apos;, function(err) &#123; console.error(&apos;Caught exception:&apos;, err.stack); &#125;); process.on(&apos;unhandledRejection&apos;, function(reason, p) &#123; console.error(&apos;Unhandled Rejection at: Promise &apos;, p, &apos; reason: &apos;, reason.stack); &#125;);&#125;//创建两个服务器实体var server = require(&apos;http&apos;).createServer(app);var server1 = require(&apos;http&apos;).createServer(app);//服务器监听端口var PORT = parseInt(process.env.PORT || 3000);var PORT1 = PORT + 1;server.listen(PORT, function (err) &#123; console.log(&apos;Node app is running on port:&apos;, PORT); catchGlobalError(err);&#125;);server1.listen(PORT1, function (err) &#123; console.log(&apos;Node app is running on port:&apos;, PORT1); catchGlobalError(err);&#125;); 根目录/views/error.ejs123456789101112&lt;!DOCTYPE HTML&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Error&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/stylesheets/style.css&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;%= message %&gt;&lt;/h1&gt; &lt;h2&gt;&lt;%= error.status %&gt;&lt;/h2&gt; &lt;pre&gt;&lt;%= error.stack %&gt;&lt;/pre&gt; &lt;/body&gt;&lt;/html&gt; 根目录/views/index.ejs12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang=&quot;zh-CN&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt; &lt;title&gt;nodejs 和 nginx&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;./stylesheets/style.css&quot;&gt;&lt;/head&gt; &lt;body&gt; &lt;p&gt;&lt;h3&gt;Hello world&lt;/h3&gt;&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; ngnix配置文件nginx.config 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream nodeproxy &#123; server 192.168.10.137:3000 weight=10; server 127.0.0.1:3001 weight=12; &#125; server &#123; listen 8089; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; proxy_pass http://nodeproxy; #与upstream的名称一致 proxy_redirect default; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; nginx常用命令在nginx的安装根目录下，打开命令行工具，运行。 启动nginx：start nginx重新加载配置：nginx -s reload重新打开日志：nginx -s reopen 关闭nginx：快速停止：nginx -s stop有序关闭：nginx -s quit 如果遇到启动不了nginx，可能是监听的端口被占用。使用命令：netstat -aon | findstr :80查询一下 用浏览器访问localhost:8089,我的测试的结果是： “D:\\WebStorm 2017.2.1\\bin\\runnerw.exe” D:\\nodejs\\node.exe D:\\collect\\leancloud\\jiangebuluo\\NodeTestDemo\\myServer.jsNode app is running on port: 3000Node app is running on port: 3001服务器监听的IP: 192.168.10.137服务器监听的IP: 192.168.10.137服务器监听的IP: 127.0.0.1服务器监听的IP: 127.0.0.1服务器监听的IP: 127.0.0.1服务器监听的IP: 127.0.0.1服务器监听的IP: 127.0.0.1服务器监听的IP: 127.0.0.1服务器监听的IP: 192.168.10.137服务器监听的IP: 192.168.10.137 最后另外贴出一个ubuntu的详细配置讲解。来自猎手家园的博客123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328#定义Nginx运行的用户和用户组user www www;#nginx进程数，建议设置为等于CPU总核心数。worker_processes 8; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /usr/local/nginx/logs/error.log info;#进程pid文件pid /usr/local/nginx/logs/nginx.pid;#指定进程可以打开的最大描述符：数目#工作模式与连接数上限#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。worker_rlimit_nofile 65535;events&#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。 worker_connections 65535; #keepalive超时时间。 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #4096 #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on;&#125; #设定http服务器，利用它的反向代理功能提供负载均衡支持http&#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 #charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream piao.jd.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 127.0.0.1:3000 weight=3; server 127.0.0.1:3001 weight=2; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 #例如： #upstream bakend &#123; # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #&#125; #2、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 #例如： #upstream bakend &#123; # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #&#125; #3、fair（第三方） #按后端服务器的响应时间来分配请求，响应时间短的优先分配。 #upstream backend &#123; # server server1; # server server2; # fair; #&#125; #4、url_hash（第三方） #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 #upstream backend &#123; # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #&#125; #tips: #upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123; # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #&#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为: #1.down表示单前的server暂时不参与负载 #2.weight为weight越大，负载的权重就越大。 #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4.fail_timeout:max_fails次失败后，暂停的时间。 #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。 #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug #client_body_temp_path设置记录文件的目录 可以设置最多3层目录 #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.jd.com jd.com; index index.html index.htm index.php; root /data/www/jd; #对******进行负载均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址； #$remote_user：用来记录客户端用户名称； #$time_local： 用来记录访问时间与时区； #$request： 用来记录请求的url与http协议； #$status： 用来记录请求状态；成功是200， #$body_bytes_sent ：记录发送给客户端文件主体内容大小； #$http_referer：用来记录从那个页面链接访问过来的； #$http_user_agent：记录客户浏览器的相关信息； #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。 log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 &quot;/&quot; 启用反向代理 location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic &quot;NginxStatus&quot;; auth_basic_user_file confpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt| pdf|xls|mp3|wma)$ &#123; expires 15d; &#125; location ~ .*.(js|css)?$ &#123; expires 1h; &#125; &#125;&#125;","categories":[],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://zhangsunyucong.top/tags/nodejs/"}]},{"title":"第一个tensorflow程序","slug":"第一个tensorflow程序","date":"2017-11-24T14:16:43.000Z","updated":"2018-01-12T06:03:01.106Z","comments":true,"path":"2017/11/24/第一个tensorflow程序/","link":"","permalink":"http://zhangsunyucong.top/2017/11/24/第一个tensorflow程序/","excerpt":"最近AlphaGo和AlphaZero的出现，预示着2017年成为人工智能元年，人工智能逐渐进入我们的生活和工作的方方面面，如在工作中，阿里巴巴双十一中，出现了“千人千面”智能推荐系统，鲁班AI设计师，小蜜机器人，IDC智能巡检机器人，还有京东的无人仓库等。这些都让我觉得人工智能越来越重要和越来越感兴趣，所以决定学习python和tensorflow。现在就以一个使用tensorflow构建一元线性模型开始我的人工智能学习吧。","text":"最近AlphaGo和AlphaZero的出现，预示着2017年成为人工智能元年，人工智能逐渐进入我们的生活和工作的方方面面，如在工作中，阿里巴巴双十一中，出现了“千人千面”智能推荐系统，鲁班AI设计师，小蜜机器人，IDC智能巡检机器人，还有京东的无人仓库等。这些都让我觉得人工智能越来越重要和越来越感兴趣，所以决定学习python和tensorflow。现在就以一个使用tensorflow构建一元线性模型开始我的人工智能学习吧。 人工智能，机器学习，深度学习关系 人工智能是计算机学科的一个分支，诞生于1956年。机器学习是人工智能的范畴，它包含了深度学习。深度是指多层的意思，模型经过多层的神经网络的训练，不断的学习和调整模型的参数，最后得到最优损失函数最小的模型。深度学习能够有效的处理现实生活中的“非线性”问题。tensorflow是目前最受欢迎的深度学习框架。 几个tensorflow的关键词语，张量，流，计算图。更多的建议阅读：《Tensorflow实战》 下面直接上最简单的一元线性回归模型代码：电脑环境： python版本：3.6.3. tensorflow版本：cpu版，1.3 window 7 64位 IDE：PyCharm 12345678910111213141516171819202122232425262728293031import tensorflow as tfsession = tf.Session()# X轴参数w = tf.Variable([.3], dtype=tf.float32)# 偏移量b = tf.Variable([-.3], dtype=tf.float32)# x轴x = tf.placeholder(tf.float32)# 一元线性模型linear_model = w * x + b# 实际值y = tf.placeholder(tf.float32)# 观测值和实际值的误差的平方差squared_deltas = tf.square(linear_model - y)# 最少二乘法。损失函数loss = tf.reduce_sum(squared_deltas)# 优化器.优化函数optimizer = tf.train.GradientDescentOptimizer(0.01)train = optimizer.minimize(loss)# 初始化所有的变量init = tf.global_variables_initializer()session.run(init)# 开始训练。训练的过程就是结合优化函数使损失函数的损失最少x_train = [1,2,3,4]y_train = [0, -1,-2,-3]for i in range(1000): session.run(train, &#123;x: x_train, y: y_train&#125;)# 训练的结果curr_W, curr_b, curr_loss = session.run([w, b, loss], &#123;x: x_train, y: y_train&#125;)print(&quot;W: %s b: %s loss: %s&quot;%(curr_W, curr_b, curr_loss)) 模型输出结果是：1W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11 公式表示是：$Y=-0.9999969X + 0.99999082$, 损失为：5.69997e-11","categories":[],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://zhangsunyucong.top/tags/tensorflow/"}]},{"title":"第一篇博客","slug":"第一篇博客","date":"2017-11-24T11:25:11.000Z","updated":"2018-01-12T06:03:01.108Z","comments":true,"path":"2017/11/24/第一篇博客/","link":"","permalink":"http://zhangsunyucong.top/2017/11/24/第一篇博客/","excerpt":"","text":"我想了许久，我建立个人博客网站，第一篇文章应该写什么呢？自从毕业以来，我很久没有写过记录的文章了，加上自己的写作能力，呵呵我是一个在空闲时，总是善于回忆的人。所以我决定将一首高三时对我有深刻影响的词作为博客的第一篇文章。 这首词，在我高三最迷茫自暴自弃的时候，让我重新找到努力的力量，我还可以忘记以前的一切，可以重新开始。无论你之前是如何的失败和消沉，如果你有不计自己的损失，还可以让你的心和脑再次专注，只要坚持挺住，那结果必有回响。 如果你能倾毕生心血,去冒险进行孤注一掷.失败后一切从头再来,而绝口不提你的损失.如果你曾经消沉许多,还能使你的心脑重又专注.坚持哪怕你一无所有,惟剩一种意志在命令,挺住! 此词 与大家共勉 new APlayer({ element: document.getElementById(\"aplayer0\"), narrow: false, autoplay: false, showlrc: 0, music: { title: \"够钟\", author: \"周柏豪\", url: \"http://o8bym0zmt.bkt.clouddn.com/%E5%91%A8%E6%9F%8F%E8%B1%AA%20-%20%E5%A4%9F%E9%92%9F.mp3\", pic: \"\", } });","categories":[],"tags":[{"name":"生活","slug":"生活","permalink":"http://zhangsunyucong.top/tags/生活/"}]}]}